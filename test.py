# æ–‡ä»¶: validate.py
# èŒè´£: åŠ è½½å¯¼å‡ºçš„ONNXæ¨¡å‹ï¼Œå¯¹éªŒè¯é›†ä¸­çš„éšæœºå›¾ç‰‡è¿›è¡Œæ¨ç†ï¼Œ
#       å¹¶å°†æ£€æµ‹ç»“æœï¼ˆè¾¹ç•Œæ¡†å’Œæ ‡ç­¾ï¼‰å¯è§†åŒ–åœ°ç»˜åˆ¶å‡ºæ¥ï¼Œä»¥ä¾›äººå·¥è¯„ä¼°ã€‚

import cv2
import numpy as np
import onnxruntime as ort
import yaml
from pathlib import Path
import random

# --- [æ ¸å¿ƒé…ç½®] ---
# æŒ‡å‘æ‚¨åˆšåˆšå¯¼å‡ºçš„ã€éœ€è¦è¢«éªŒè¯çš„æ¨¡å‹
MODEL_PATH = Path("saved/models/yolo_v1.onnx")

# æŒ‡å‘æ•°æ®å‡†å¤‡é˜¶æ®µç”Ÿæˆçš„ dataset.yaml æ–‡ä»¶ï¼Œä»¥æ‰¾åˆ°éªŒè¯é›†å’Œç±»åˆ«å
DATASET_YAML_PATH = Path("data/processed/finetune_v2_input/dataset.yaml") 

# åœ¨æ­¤ç›®å½•ä¸­æŸ¥çœ‹æ‚¨æ¨¡å‹çš„â€œç­”å·â€
OUTPUT_DIR = Path("validation_results")

# --- [æ¨ç†è¶…å‚æ•°] ---
# æ¨¡å‹è¾“å…¥çš„å›¾åƒå°ºå¯¸
INPUT_WIDTH = 640
INPUT_HEIGHT = 640

# åªæœ‰å½“æ¨¡å‹çš„é¢„æµ‹ç½®ä¿¡åº¦é«˜äºæ­¤é˜ˆå€¼æ—¶ï¼Œæ‰ä¼šè¢«è®¤ä¸ºæ˜¯æœ‰æ•ˆæ£€æµ‹
CONF_THRESHOLD = 0.1

# NMSï¼ˆéæå¤§å€¼æŠ‘åˆ¶ï¼‰çš„é˜ˆå€¼ï¼Œç”¨äºåˆå¹¶é‡å çš„æ£€æµ‹æ¡†
IOU_THRESHOLD = 0.5


class Validator:
    """
    ä¸€ä¸ªå®Œæ•´çš„ONNXæ¨¡å‹å¯è§†åŒ–éªŒè¯å™¨ã€‚
    å®ƒå°è£…äº†ä»é¢„å¤„ç†ã€æ¨ç†åˆ°åå¤„ç†å’Œå¯è§†åŒ–çš„æ‰€æœ‰æ­¥éª¤ã€‚
    """
    def __init__(self, model_path, dataset_yaml_path):
        # 1. åŠ è½½ONNXæ¨¡å‹å¹¶åˆ›å»ºæ¨ç†ä¼šè¯
        print(f"--- ğŸš€ å¯åŠ¨YOLOv1 ONNXæ¨¡å‹å¯è§†åŒ–éªŒè¯å™¨ ---")
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
        self.session = ort.InferenceSession(str(model_path), providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])
        print(f"æ¨¡å‹åŠ è½½æˆåŠŸï¼ä½¿ç”¨çš„è®¾å¤‡: {self.session.get_providers()[0]}")
        
        # 2. ä»dataset.yamlåŠ è½½ç±»åˆ«ä¿¡æ¯å’ŒéªŒè¯é›†è·¯å¾„
        print(f"æ­£åœ¨åŠ è½½æ•°æ®é›†ä¿¡æ¯: {dataset_yaml_path}")
        with open(dataset_yaml_path, 'r', encoding='utf-8') as f:
            self.dataset_info = yaml.safe_load(f)
        self.class_names = self.dataset_info['names']
        print(f"æˆåŠŸåŠ è½½ {len(self.class_names)} ä¸ªç±»åˆ«ã€‚")
        
        # 3. å‡†å¤‡éªŒè¯å›¾ç‰‡åˆ—è¡¨
        val_images_dir = dataset_yaml_path.parent / self.dataset_info['val']
        self.val_image_paths = list(val_images_dir.glob("*.png")) + list(val_images_dir.glob("*.jpg"))
        print(f"åœ¨éªŒè¯é›†ä¸­æ‰¾åˆ° {len(self.val_image_paths)} å¼ å›¾ç‰‡ã€‚")

    def run_validation(self, num_images_to_test=5):
        """
        æ‰§è¡ŒéªŒè¯æµç¨‹ã€‚
        """
        if not self.val_image_paths:
            print("âŒ é”™è¯¯: éªŒè¯é›†ä¸­æ²¡æœ‰ä»»ä½•å›¾ç‰‡ï¼Œæ— æ³•è¿›è¡ŒéªŒè¯ã€‚")
            return
            
        OUTPUT_DIR.mkdir(exist_ok=True)
        print(f"\n--- å¼€å§‹éšæœºæŠ½å– {num_images_to_test} å¼ å›¾ç‰‡è¿›è¡ŒéªŒè¯ ---")
        print(f"ç»“æœå°†ä¿å­˜åœ¨: {OUTPUT_DIR.resolve()}")

        # éšæœºé€‰æ‹©Nå¼ å›¾ç‰‡
        selected_images = random.sample(self.val_image_paths, min(num_images_to_test, len(self.val_image_paths)))

        for i, image_path in enumerate(selected_images):
            print(f"\n[{i+1}/{num_images_to_test}] æ­£åœ¨å¤„ç†: {image_path.name}")
            
            original_image = cv2.imread(str(image_path))
            
            # 1. é¢„å¤„ç†
            input_tensor, scale, pad_left, pad_top = self._preprocess(original_image)
            
            # 2. æ¨ç†
            model_inputs = {self.session.get_inputs()[0].name: input_tensor}
            model_outputs = self.session.run(None, model_inputs)
            
            # 3. åå¤„ç†
            boxes, scores, class_ids = self._postprocess(model_outputs[0], scale, pad_left, pad_top, original_image.shape)
            
            # 4. å¯è§†åŒ–
            result_image = self._draw_detections(original_image, boxes, scores, class_ids)
            
            # 5. ä¿å­˜ç»“æœ
            output_path = OUTPUT_DIR / f"result_{image_path.name}"
            cv2.imwrite(str(output_path), result_image)
            print(f"  -> æ£€æµ‹åˆ° {len(boxes)} ä¸ªç‰©ä½“ã€‚ç»“æœå·²ä¿å­˜è‡³: {output_path.name}")

        print("\n--- âœ… éªŒè¯å®Œæˆï¼ ---")

    def _preprocess(self, image):
        """å°†OpenCVå›¾åƒè½¬æ¢ä¸ºæ¨¡å‹æ‰€éœ€çš„è¾“å…¥å¼ é‡ã€‚"""
        h, w, _ = image.shape
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹å’Œå¡«å……å°ºå¯¸
        scale = min(INPUT_WIDTH / w, INPUT_HEIGHT / h)
        unpad_w, unpad_h = int(w * scale), int(h * scale)
        pad_w, pad_h = INPUT_WIDTH - unpad_w, INPUT_HEIGHT - unpad_h
        pad_left, pad_top = pad_w // 2, pad_h // 2
        
        # ç¼©æ”¾å’Œå¡«å……
        resized_img = cv2.resize(image, (unpad_w, unpad_h))
        padded_img = cv2.copyMakeBorder(resized_img, pad_top, pad_h - pad_top, pad_left, pad_w - pad_left, cv2.BORDER_CONSTANT)
        
        # è½¬æ¢ä¸ºCHWæ ¼å¼, å½’ä¸€åŒ–, å¹¶å¢åŠ Batchç»´åº¦
        input_tensor = padded_img.transpose(2, 0, 1).astype(np.float32) / 255.0
        input_tensor = np.expand_dims(input_tensor, axis=0)
        
        return input_tensor, scale, pad_left, pad_top

    def _postprocess(self, output, scale, pad_left, pad_top, original_shape):
        """è§£ç YOLOæ¨¡å‹çš„åŸå§‹è¾“å‡ºï¼Œæ‰§è¡ŒNMSï¼Œå¹¶å°†åæ ‡æ˜ å°„å›åŸå§‹å›¾åƒã€‚"""
        # [1, 72, 8400] -> [1, 8400, 72]
        output = np.transpose(output, (0, 2, 1))[0]
        
        boxes, scores, class_ids = [], [], []
        
        for row in output:
            # [cx, cy, w, h, class_prob_0, class_prob_1, ...]
            class_probs = row[4:]
            class_id = np.argmax(class_probs)
            confidence = class_probs[class_id]
            
            if confidence > CONF_THRESHOLD:
                cx, cy, w, h = row[:4]
                
                # å°†ä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜è½¬æ¢ä¸ºå·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡
                x1 = int((cx - w / 2 - pad_left) / scale)
                y1 = int((cy - h / 2 - pad_top) / scale)
                x2 = int((cx + w / 2 - pad_left) / scale)
                y2 = int((cy + h / 2 - pad_top) / scale)
                
                boxes.append([x1, y1, x2 - x1, y2 - y1]) # NMSéœ€è¦ (x, y, w, h) æ ¼å¼
                scores.append(float(confidence))
                class_ids.append(class_id)
        
        # åº”ç”¨éæå¤§å€¼æŠ‘åˆ¶ (NMS)
        indices = cv2.dnn.NMSBoxes(boxes, scores, CONF_THRESHOLD, IOU_THRESHOLD)
        
        final_boxes, final_scores, final_class_ids = [], [], []
        if len(indices) > 0:
            for i in indices.flatten():
                final_boxes.append(boxes[i])
                final_scores.append(scores[i])
                final_class_ids.append(class_ids[i])
                
        return final_boxes, final_scores, final_class_ids

    def _draw_detections(self, image, boxes, scores, class_ids):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœã€‚"""
        for box, score, class_id in zip(boxes, scores, class_ids):
            x, y, w, h = box
            
            # è·å–ç±»åˆ«åå’Œé¢œè‰²
            label = self.class_names.get(class_id, f"ID:{class_id}")
            color = (0, 255, 0) # ç»¿è‰²
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)
            
            # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
            text = f"{label}: {score:.2f}"
            
            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
            (text_w, text_h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            cv2.rectangle(image, (x, y - text_h - 5), (x + text_w, y), color, -1)
            
            # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
            cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
            
        return image


if __name__ == "__main__":
    if not MODEL_PATH.exists():
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {MODEL_PATH}")
    elif not DATASET_YAML_PATH.exists():
        print(f"âŒ é”™è¯¯: æ•°æ®é›†é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {DATASET_YAML_PATH}")
    else:
        validator = Validator(MODEL_PATH, DATASET_YAML_PATH)
        validator.run_validation(num_images_to_test=10) # æ‚¨å¯ä»¥ä¿®æ”¹è¿™é‡Œæ¥æµ‹è¯•æ›´å¤šå›¾ç‰‡