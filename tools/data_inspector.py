# æ–‡ä»¶: /home/zhz/deepl/tools/data_inspector.py
# èŒè´£: æ‰«ææŒ‡å®šçš„æ ‡æ³¨æ•°æ®æºï¼Œç»Ÿè®¡æ‰€æœ‰ç±»åˆ«çš„å®ä¾‹æ•°é‡ï¼Œ
#       å¹¶ç”Ÿæˆä¸€ä»½ç¨€ç¼ºç±»åˆ«æ¸…å•ï¼Œç”¨äºæŒ‡å¯¼åç»­çš„æ•°æ®åˆæˆã€‚

import json
from pathlib import Path
from collections import Counter
import argparse
from tqdm import tqdm

# --- [æ ¸å¿ƒé…ç½®] ---
# è„šæœ¬ä¼šè‡ªåŠ¨è®¡ç®—é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).resolve().parents[1]

# ã€è¯·ç¡®è®¤ã€‘è¿™é‡ŒæŒ‡å‘æ‚¨æ•´åˆäº†æ‰€æœ‰çœŸå®æ•°æ®çš„æºæ–‡ä»¶å¤¹
DATA_SOURCE_DIR = PROJECT_ROOT / "data/raw/real_data_combined_v1"

# ã€å¯è°ƒæ•´ã€‘å½“ä¸€ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡ä½äºæ­¤é˜ˆå€¼æ—¶ï¼Œå®ƒå°†è¢«åˆ—ä¸ºâ€œç¨€ç¼ºç±»åˆ«â€
DEFAULT_SCARCITY_THRESHOLD = 20

def analyze_class_distribution(data_dir: Path, threshold: int):
    """
    åˆ†ææŒ‡å®šç›®å½•ä¸­æ‰€æœ‰LabelMe .jsonæ–‡ä»¶çš„ç±»åˆ«åˆ†å¸ƒã€‚
    """
    print("--- ğŸš€ å¯åŠ¨æ•°æ®é›†ç±»åˆ«åˆ†å¸ƒåˆ†æå™¨ ---")
    if not data_dir.is_dir():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®æºç›®å½•: {data_dir}")
        return

    json_files = list(data_dir.glob("*.json"))
    if not json_files:
        print(f"âŒ é”™è¯¯: åœ¨ {data_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½• .json æ–‡ä»¶ã€‚")
        return

    print(f"ğŸ” æ­£åœ¨æ‰«æ {len(json_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶...")

    class_counter = Counter()

    for json_path in tqdm(json_files, desc="åˆ†æè¿›åº¦"):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            for shape in data.get('shapes', []):
                label_with_prefix = shape.get('label', '')
                if not label_with_prefix:
                    continue
                
                # ã€å…³é”®ã€‘ä½¿ç”¨ä¸è®­ç»ƒæ—¶å®Œå…¨ç›¸åŒçš„è§£æé€»è¾‘ï¼
                # ä» '1a-é™ªç»ƒ' æˆ– '1-unit-enemy-mob-å¤§æµ·é¾Ÿ' ä¸­è§£æå‡ºæ ¸å¿ƒç±»åˆ«å
                class_name = label_with_prefix.rsplit('-', 1)[-1]
                class_counter[class_name] += 1
        except Exception as e:
            print(f"\nâš ï¸ è­¦å‘Š: å¤„ç†æ–‡ä»¶ {json_path.name} æ—¶å‡ºé”™: {e}")

    if not class_counter:
        print("âŒ åˆ†æå®Œæˆï¼Œä½†æœªç»Ÿè®¡åˆ°ä»»ä½•ç±»åˆ«ã€‚è¯·æ£€æŸ¥æ‚¨çš„.jsonæ–‡ä»¶å†…å®¹ã€‚")
        return
        
    print("\n" + "="*80)
    print("--- âœ… æ•°æ®é›†ç±»åˆ«åˆ†å¸ƒåˆ†ææŠ¥å‘Š ---")
    print(f"   - æ‰«æç›®å½•: {data_dir}")
    print(f"   - æ€»è®¡å‘ç° {len(class_counter)} ä¸ªç‹¬ç«‹ç±»åˆ«ã€‚")
    print("="*80)

    # 1. æ‰“å°å®Œæ•´çš„ç±»åˆ«åˆ†å¸ƒæƒ…å†µ
    print("\n--- [å®Œæ•´ç±»åˆ«åˆ†å¸ƒ] (æŒ‰æ•°é‡é™åº) ---")
    print(f"{'æ’å':<5} | {'ç±»åˆ«åç§°':<20} | {'å®ä¾‹æ•°é‡':<10}")
    print("-" * 45)
    for i, (class_name, count) in enumerate(class_counter.most_common()):
        print(f"{i+1:<5} | {class_name:<20} | {count:<10}")

    # 2. ç­›é€‰å¹¶æ‰“å°ç¨€ç¼ºç±»åˆ«æ¸…å•
    print("\n" + "="*80)
    print(f"--- [ç¨€ç¼ºç±»åˆ«æ¸…å•] (æ ·æœ¬æ•° < {threshold}) ---")
    print("="*80)
    
    scarce_classes = []
    for class_name, count in sorted(class_counter.items(), key=lambda item: item[1]):
        if count < threshold:
            scarce_classes.append(class_name)
            print(f"   - {class_name:<20} | ä»…æœ‰ {count} ä¸ªæ ·æœ¬")

    if not scarce_classes:
        print("ğŸ‰ æ­å–œï¼æ²¡æœ‰å‘ç°ä»»ä½•ä½äºé˜ˆå€¼çš„ç¨€ç¼ºç±»åˆ«ã€‚")
    
    # 3. è¾“å‡ºæœ€ç»ˆå¯ç”¨çš„æ¸…å•
    print("\n" + "="*80)
    print("--- ğŸ“‹ [æœ€ç»ˆç¨€ç¼ºç±»åˆ«æ¸…å•] (å¯ç›´æ¥ç”¨äºæŒ‡å¯¼æ•°æ®åˆæˆ) ---")
    print("="*80)
    print(scarce_classes)
    print("\n--- åˆ†æå®Œæˆ ---")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="åˆ†æLabelMeæ•°æ®é›†çš„ç±»åˆ«åˆ†å¸ƒå¹¶æ‰¾å‡ºç¨€ç¼ºç±»åˆ«ã€‚")
    parser.add_argument(
        '-t', '--threshold', 
        type=int, 
        default=DEFAULT_SCARCITY_THRESHOLD,
        help=f"å®šä¹‰ç¨€ç¼ºç±»åˆ«çš„æ•°é‡é˜ˆå€¼ (é»˜è®¤: {DEFAULT_SCARCITY_THRESHOLD})"
    )
    args = parser.parse_args()
    
    analyze_class_distribution(DATA_SOURCE_DIR, args.threshold)